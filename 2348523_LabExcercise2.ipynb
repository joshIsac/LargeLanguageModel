{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1c5SmlfjkPjS8zWiIUIl5uAJfuk4MrMM5",
      "authorship_tag": "ABX9TyP9zSbZfexObis8MtjvtURc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshIsac/LargeLanguageModel/blob/main/2348523_LabExcercise2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_groq"
      ],
      "metadata": {
        "id": "CC7-Umix4OzR",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb48fcd0-1216-4b36-efce-40d20bb9555d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.7-py3-none-any.whl (983 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/983.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m983.0/983.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.6/983.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.12 (from langchain)\n",
            "  Downloading langchain_core-0.2.13-py3-none-any.whl (357 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.9/357.9 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.85-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.12->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.7 langchain-core-0.2.13 langchain-text-splitters-0.2.2 langsmith-0.1.85 orjson-3.10.6\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.1.6-py3-none-any.whl (14 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.2.13)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_groq) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_groq) (0.1.85)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_groq) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_groq) (8.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_groq) (3.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_groq) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_groq) (2.0.7)\n",
            "Installing collected packages: h11, httpcore, httpx, groq, langchain_groq\n",
            "Successfully installed groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain_groq-0.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv==1.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "300VhLX_6BDW",
        "outputId": "e13e2f38-c949-42b8-f900-eacded4d8dfb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv==1.0.0\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2noXNHkF4Hvw"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_groq import ChatGroq\n",
        "from dotenv import load_dotenv\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "#getting the API KEY\n",
        "api_key = \"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\"\n",
        "\n",
        "print(api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc3c2VpP5mC3",
        "outputId": "78a07445-4a51-454b-afe6-5f54b3deed24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groqAPI_model=ChatGroq(api_key=api_key, model_name='gemma-7b-it')\n"
      ],
      "metadata": {
        "id": "4AgWblyu9Sl9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your prompt template\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = [\"topic\"],\n",
        "    template=\"What is {topic}?\"\n",
        ")"
      ],
      "metadata": {
        "id": "GQ0Mx_09_d7C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parser=StrOutputParser()\n",
        "# # Create a chain with the prompt and parser\n",
        "# chainSec = prompt | groqAPI_model | parser\n",
        "# # Invoke the chain with your input\n",
        "# chainSec.invoke({\"topic\": \"cybersecurity\"})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Do_-TcKRApRK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an interactive prompt for question and answering using the above model\n",
        "while True:\n",
        "  topic = input(\"Enter a topic (or type 'quit' to exit): \")\n",
        "  if topic.lower() == 'quit':\n",
        "    break\n",
        "  response = chainSec.invoke({\"topic\": topic})\n",
        "  print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpdlqlFijtYj",
        "outputId": "b81e723c-42be-4541-d837-55d84f7392e1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a topic (or type 'quit' to exit): suck\n",
            "Please provide me with a specific question about the word \"suck.\" \n",
            "\n",
            "For example, you could ask:\n",
            "\n",
            "* **What are some different meanings of the word \"suck\"?**\n",
            "* **Can you give me an example of how \"suck\" can be used in a sentence?**\n",
            "* **Is \"suck\" considered a vulgar word?**\n",
            "* **What is the etymology of the word \"suck\"?**\n",
            "\n",
            "\n",
            "The more specific your question, the better I can answer it! \n",
            "\n",
            "\n",
            "Enter a topic (or type 'quit' to exit): Is \"suck\" considered a vulgar word?\n",
            "Yes, \"suck\" is generally considered a vulgar word. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "* **Sexual connotations:**  The word often has explicit sexual meanings, particularly when used as a verb.\n",
            "* **Crude imagery:** It evokes unpleasant images associated with bodily functions.\n",
            "* **Insulting tone:** It can be used as a derogatory term, expressing disapproval or contempt.\n",
            "\n",
            "**However, context matters.**\n",
            "\n",
            "* **Informal settings:**  \"Suck\" can be used in casual conversation to express strong dislike or frustration. For example, \"This movie sucks!\"\n",
            "* **Slang:**  It has various slang meanings, some of which are not necessarily vulgar. \n",
            "\n",
            "**Ultimately, whether \"suck\" is considered vulgar depends on the situation, the speaker's intent, and the audience.** It's generally best to avoid using it in formal settings or when speaking to people you don't know well.\n",
            "\n",
            "Enter a topic (or type 'quit' to exit): quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using different model\n",
        "groqAPI_model=ChatGroq(api_key=api_key, model_name='llama3-70b-8192')\n",
        "parser=StrOutputParser()\n",
        "chainSec = prompt | groqAPI_model | parser\n",
        "\n",
        "\n",
        "# create an interactive prompt for question and answering using the above model\n",
        "while True:\n",
        "  topic = input(\"Enter a topic (or type 'quit' to exit): \")\n",
        "  if topic.lower() == 'quit':\n",
        "    break\n",
        "  response = chainSec.invoke({\"topic\": topic})\n",
        "  print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXM2dtbolj1F",
        "outputId": "770d3730-5b82-4ecf-e365-bcb94bec0e59"
      },
      "execution_count": 33,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a topic (or type 'quit' to exit): let us talk about chess\n",
            "What a great topic! I'm excited to chat with you about chess. As a question-answering expert, I'm ready to tackle any questions you have about this fascinating game.\n",
            "\n",
            "Would you like to discuss:\n",
            "\n",
            "1. Basic rules and strategies?\n",
            "2. Famous chess players and their contributions?\n",
            "3. Opening theories and responses?\n",
            "4. Endgame techniques and tactics?\n",
            "5. Chess variants and alternative forms of the game?\n",
            "6. The history of chess and its evolution?\n",
            "7. Computer chess and AI developments?\n",
            "8. Something else entirely?\n",
            "\n",
            "Let me know, and I'll do my best to provide insightful answers!\n",
            "Enter a topic (or type 'quit' to exit): famous chess players and their contribution\n",
            "A fascinating topic!\n",
            "\n",
            "I'm ready to answer your questions about famous chess players and their contributions to the game. Go ahead and ask me anything!\n",
            "\n",
            "Would you like to know about:\n",
            "\n",
            "* The legendary World Champions like Bobby Fischer, Garry Kasparov, or Emanuel Lasker?\n",
            "* The contributions of pioneers like Ruy López de Segura, François-André Danican Philidor, or Adolf Anderssen?\n",
            "* The impact of modern players like Magnus Carlsen, Viswanathan Anand, or Sergey Karjakin on the game?\n",
            "* The role of chess players in popularizing the game, like Paul Morphy or José Capablanca?\n",
            "* Or perhaps the strategic innovations of players like Aron Nimzowitsch, Richard Réti, or Mikhail Botvinnik?\n",
            "\n",
            "Fire away with your questions!\n",
            "Enter a topic (or type 'quit' to exit): quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using different model\n",
        "groqAPI_model=ChatGroq(api_key=api_key, model_name='gemma2-9b-it')\n",
        "parser=StrOutputParser()\n",
        "chainSec = prompt | groqAPI_model | parser\n",
        "\n",
        "\n",
        "# create an interactive prompt for question and answering using the above model\n",
        "while True:\n",
        "  topic = input(\"Enter a topic (or type 'quit' to exit): \")\n",
        "  if topic.lower() == 'quit':\n",
        "    break\n",
        "  response = chainSec.invoke({\"topic\": topic})\n",
        "  print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mPEoBZJoWNc",
        "outputId": "4e22c415-0f01-41f2-f4f5-616942d1754d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a topic (or type 'quit' to exit): let us talk about chess\n",
            "I'm ready to talk chess! ♟️  \n",
            "\n",
            "What would you like to discuss? \n",
            "\n",
            "For example, I can:\n",
            "\n",
            "* **Answer questions about chess rules and strategy.**\n",
            "* **Analyze a specific chess position.**\n",
            "* **Discuss famous chess players or games.**\n",
            "* **Provide chess puzzles for you to solve.**\n",
            "* **Talk about the history of chess.**\n",
            "\n",
            "Just let me know what's on your mind! 🧠  \n",
            "\n",
            "\n",
            "Enter a topic (or type 'quit' to exit): what about Rules and regulation?\n",
            "Please give me a more specific question about rules and regulations! I need some context to provide a helpful answer.  \n",
            "\n",
            "For example, you could ask:\n",
            "\n",
            "* **What are the rules and regulations surrounding [specific activity or industry]?** (e.g., \"What are the rules and regulations surrounding drone usage?\")\n",
            "* **What is the purpose of rules and regulations?**\n",
            "* **How are rules and regulations made?**\n",
            "* **What are the consequences of breaking rules and regulations?**\n",
            "* **Can rules and regulations be changed? How?**\n",
            "\n",
            "\n",
            "The more specific your question, the better I can understand what you're looking for and give you a relevant and informative answer. \n",
            "\n",
            "\n",
            "Enter a topic (or type 'quit' to exit): Rules and regulation in chess i mean\n",
            "Let's talk chess rules! I'm happy to answer your questions about the regulations of this fascinating game.  \n",
            "\n",
            "To make things easier, could you be a bit more specific about what you'd like to know? For example, are you interested in:\n",
            "\n",
            "* **Basic movement rules for each piece?** (e.g., how a pawn moves, how a knight jumps)\n",
            "* **Special moves?** (e.g., castling, en passant, promotion)\n",
            "* **Game setup and starting positions?**\n",
            "* **Winning conditions?** (e.g., checkmate, stalemate, resignation)\n",
            "* **Fouls and penalties?**\n",
            "* **Rules for tournaments and competitive play?** \n",
            "\n",
            "Let me know, and I'll provide you with accurate and clear information. \n",
            "\n",
            "\n",
            "Enter a topic (or type 'quit' to exit): quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt_template = (\n",
        "#     \"\"\"\n",
        "#    You are an formula 1 Question answering expert  that provides the details only about formula 1 any irrelevant question provide an answer stating that im anot aware about the question that you have provided\n",
        "# topic : {topic}\n",
        "# \"\"\"\n",
        "# )\n",
        "\n",
        "# prompt = PromptTemplate.from_template(template=template)\n",
        "# chainSec = prompt | groqAPI_model | parser\n",
        "\n",
        "\n",
        "\n",
        "# question=\"\"\"what are technologies involved in Formula 1\"\"\"\n",
        "# chainSec.invoke({\"topic\": question})\n",
        "# print(chainSec.invoke({\"topic\": question}))"
      ],
      "metadata": {
        "id": "TmUdUdliAZyN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have used langchain by importing Groq chat for creating interactive question answer modeling by entering any of your favourite topic and the required answer is provided\n"
      ],
      "metadata": {
        "id": "RaJ8M7SftkHK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7jZETDw9CCDq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWw69g6XBvxS"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}